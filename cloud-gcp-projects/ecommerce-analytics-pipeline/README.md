# ğŸ›’ E-commerce Analytics Pipeline - GCP

**End-to-End ETL Pipeline for E-commerce Data Analytics using Google Cloud Platform**

## ğŸ¯ Project Overview

This project implements a comprehensive data pipeline for e-commerce analytics using GCP services. The pipeline processes customer orders, product data, and web analytics to provide actionable business insights.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚    â”‚   Processing    â”‚    â”‚   Analytics     â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ CSV Files     â”‚â”€â”€â”€â–ºâ”‚ â€¢ Cloud Dataflowâ”‚â”€â”€â”€â–ºâ”‚ â€¢ BigQuery      â”‚
â”‚ â€¢ JSON APIs     â”‚    â”‚ â€¢ Cloud Functionsâ”‚   â”‚ â€¢ Looker Studio â”‚
â”‚ â€¢ Database      â”‚    â”‚ â€¢ Cloud Run     â”‚    â”‚ â€¢ BigQuery ML   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Storage       â”‚    â”‚ Orchestration   â”‚    â”‚   Monitoring    â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Cloud Storage â”‚    â”‚ â€¢ Cloud Composerâ”‚    â”‚ â€¢ Cloud Monitoringâ”‚
â”‚ â€¢ BigQuery      â”‚    â”‚ â€¢ Cloud Schedulerâ”‚   â”‚ â€¢ Cloud Logging â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### 1. Prerequisites
- Google Cloud Platform account
- Google Cloud SDK installed
- Python 3.9+
- Terraform (for infrastructure)

### 2. Setup
```bash
# Clone and setup
git clone <repository>
cd ecommerce-analytics-pipeline

# Install dependencies
pip install -r requirements.txt

# Setup GCP credentials
gcloud auth application-default login

# Deploy infrastructure
cd terraform
terraform init
terraform plan
terraform apply
```

### 3. Run Pipeline
```bash
# Start the pipeline
python src/main.py

# Or use Cloud Composer
gcloud composer environments run <env-name> --location <location> trigger_dag -- ecommerce_pipeline
```

## ğŸ“ Project Structure

```
ecommerce-analytics-pipeline/
â”œâ”€â”€ ğŸ“ data/                    # Data files
â”‚   â”œâ”€â”€ ğŸ“ raw/                # Raw data sources
â”‚   â”œâ”€â”€ ğŸ“ processed/          # Intermediate processed data
â”‚   â””â”€â”€ ğŸ“ curated/            # Final curated datasets
â”œâ”€â”€ ğŸ“ src/                     # Source code
â”‚   â”œâ”€â”€ ğŸ“ extractors/         # Data extraction modules
â”‚   â”œâ”€â”€ ğŸ“ transformers/       # Data transformation logic
â”‚   â”œâ”€â”€ ğŸ“ loaders/            # Data loading modules
â”‚   â””â”€â”€ ğŸ“ utils/              # Utility functions
â”œâ”€â”€ ğŸ“ scripts/                 # Utility scripts
â”œâ”€â”€ ğŸ“ config/                  # Configuration files
â”‚   â”œâ”€â”€ ğŸ“ environments/       # Environment configs
â”‚   â””â”€â”€ ğŸ“ credentials/        # Credential management
â”œâ”€â”€ ğŸ“ dags/                    # Airflow DAGs
â”œâ”€â”€ ğŸ“ notebooks/               # Jupyter notebooks
â”œâ”€â”€ ğŸ“ docs/                    # Documentation
â”œâ”€â”€ ğŸ“ terraform/               # Infrastructure as Code
â”œâ”€â”€ ğŸ“„ requirements.txt         # Python dependencies
â”œâ”€â”€ ğŸ“„ main.py                  # Main pipeline entry point
â””â”€â”€ ğŸ“„ README.md                # This file
```

## ğŸ› ï¸ GCP Services

### **Data Processing**
- **Cloud Dataflow**: Apache Beam pipelines for data transformation
- **Cloud Functions**: Serverless data processing
- **Cloud Run**: Containerized data processing services

### **Storage & Analytics**
- **Cloud Storage**: Data lake storage (raw, processed, curated)
- **BigQuery**: Data warehouse and analytics
- **BigQuery ML**: Machine learning models

### **Orchestration**
- **Cloud Composer**: Apache Airflow managed service
- **Cloud Scheduler**: Automated job scheduling
- **Cloud Build**: CI/CD pipeline

### **Monitoring & Security**
- **Cloud Monitoring**: Performance and health monitoring
- **Cloud Logging**: Centralized logging
- **IAM**: Identity and access management
- **VPC**: Network security

## ğŸ“Š Data Pipeline

### **1. Data Extraction**
- **Customer Orders**: CSV files from ERP system
- **Product Catalog**: JSON API from product management system
- **Web Analytics**: Google Analytics 4 data export
- **Inventory**: Database exports from warehouse system

### **2. Data Transformation**
- **Data Cleaning**: Remove duplicates, handle missing values
- **Data Enrichment**: Add calculated fields, geocoding
- **Data Aggregation**: Daily, weekly, monthly summaries
- **Data Quality**: Validation rules and checks

### **3. Data Loading**
- **Raw Layer**: Store original data in Cloud Storage
- **Processed Layer**: Store cleaned data in BigQuery
- **Curated Layer**: Store business-ready datasets

## ğŸ”§ Configuration

### **Environment Variables**
```bash
# GCP Configuration
GOOGLE_CLOUD_PROJECT=your-project-id
GOOGLE_CLOUD_REGION=us-central1
GOOGLE_CLOUD_ZONE=us-central1-a

# BigQuery Configuration
BIGQUERY_DATASET=ecommerce_analytics
BIGQUERY_LOCATION=US

# Cloud Storage Configuration
GCS_BUCKET=ecommerce-data-lake
GCS_RAW_PREFIX=raw
GCS_PROCESSED_PREFIX=processed
GCS_CURATED_PREFIX=curated
```

### **Service Account Permissions**
- BigQuery Admin
- Cloud Storage Admin
- Dataflow Admin
- Cloud Composer Admin
- Cloud Functions Admin

## ğŸ“ˆ Analytics & Insights

### **Key Metrics**
- **Revenue Analytics**: Daily sales, product performance
- **Customer Analytics**: Segmentation, lifetime value
- **Inventory Analytics**: Stock levels, turnover rates
- **Marketing Analytics**: Campaign performance, ROI

### **Dashboards**
- **Executive Dashboard**: High-level KPIs and trends
- **Operational Dashboard**: Daily operations and alerts
- **Analytical Dashboard**: Deep-dive analysis and insights

## ğŸ§ª Testing

```bash
# Run unit tests
python -m pytest tests/unit/

# Run integration tests
python -m pytest tests/integration/

# Run data quality tests
python scripts/run_data_quality_tests.py

# Run performance tests
python scripts/run_performance_tests.py
```

## ğŸ“Š Monitoring & Alerting

### **Key Metrics**
- Pipeline execution time
- Data quality scores
- Error rates and types
- Resource utilization

### **Alerts**
- Pipeline failures
- Data quality issues
- Performance degradation
- Security incidents

## ğŸ” Security

- **Data Encryption**: At rest and in transit
- **Access Control**: IAM roles and permissions
- **Audit Logging**: All data access logged
- **Network Security**: VPC and firewall rules
- **Compliance**: GDPR, CCPA, SOC2

## ğŸš€ Deployment

### **Development**
```bash
# Local development
python src/main.py --env dev

# Local testing
docker-compose up -d
```

### **Staging**
```bash
# Deploy to staging
gcloud app deploy --version staging
```

### **Production**
```bash
# Deploy to production
gcloud app deploy --version production
```

## ğŸ“š Documentation

- **[API Documentation](docs/API.md)**: Service endpoints and usage
- **[Data Dictionary](docs/DATA_DICTIONARY.md)**: Field definitions and business logic
- **[Deployment Guide](docs/DEPLOYMENT.md)**: Step-by-step deployment instructions
- **[Troubleshooting](docs/TROUBLESHOOTING.md)**: Common issues and solutions

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/your-repo/issues)
- **Documentation**: [docs/](docs/)
- **Email**: support@yourcompany.com

---

**ğŸ›’ E-commerce Analytics Pipeline - Powered by Google Cloud Platform**

*Built with â¤ï¸ using modern data engineering practices*
